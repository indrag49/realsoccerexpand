---
title: Pass Network Analysis
author: Indranil Ghosh
date: '2021-04-28'
slug: pass-network-analysis
categories: ["Python", "visualization", "NetworkX"]
tags: ["statsbomb api", "NetworkX", "Network Analysis", "Pass Network"]
subtitle: ''
summary: ''
authors: []
lastmod: '2021-04-28T10:15:58+05:30'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

In our [last tutorial](https://realsoccerexpand.netlify.app/post/pass-map-shot-map-and-heat-map/) we studied how to draw a pass map, a shot map and their corresponding heat maps. We used statsbomb's open even data from the match between *Real Madrid* and *Barcelona*, which *Real Madrid* ended up winning 2-0. In this post we will again use statsbomb's open event passing data (from a separate game this time, which we will decide on the go) and visualize the resulting pass network of a particular team on the football pitch. We will then use basic concepts from complex network analysis literature to further analyze the network and deduce some results. We will employ the [`NetworkX`](https://networkx.org/) Python package for the analysis purpose. 

Let us `pip` install the package:

```{python eval=FALSE}
pip install networkx
```

After installing the package we will import all the necessary packages and modules:

```{python}
from statsbombpy import sb # statsbomb api
import matplotlib.pyplot as plt # matplotlib for plotting
from mplsoccer.pitch import Pitch # for drawing the football pitch
import seaborn as sns # seaborn for plotting useful statistical graphs
import numpy as np # numerical python package
import pandas as pd # pandas for manipulating and analysing data
import networkx as nx # package for complex network analysis
```

Let us again work step by step to fetch the event data from a particular match:

```{python results=FALSE}
comp = sb.competitions()
```

```{python}
print(comp.to_markdown())
```

Let us use the first row from `comp` where the `competition_id` is `16` and `season_id` is `4`. We see that it holds the event data from *UEFA Champions League* ⚽ for the 2017-18 season. Let us now extract out the matches using the above information.

```{python results=FALSE}
mat = sb.matches(competition_id = 16, season_id = 1)
```

```{python}
print(mat.to_markdown())
```

We see there is only one match available, having `match_id` set to `18245`. It represents the final that took place between *Real Madrid* and *Liverpool* at *Olimpiyskiy National Sports Complex, Moscow* and Real Madrid won with the full time score: 3-1. Finally let us draw out the complete event data from this match:

```{python results=FALSE}
events = sb.events(match_id = 18245)
```

We will print the first and the last 10 rows of the dataset to get an idea of how it looks and what information it provides us with:

```{python}
print(events.head(10).to_markdown())
```

```{python}
print(events.tail(10).to_markdown())
```

As we have been usually doing till now, let us print out the column names of `events` to get an overview of the relevant and the unnecessary rows for this tutorial.

```{python}
print(events.columns)
```

If we look into the `events` dataset, we notice that the `tactics` column provides us with team lineups, formations, player ids and their jersey number from both the teams. The corresponding row values for column `type` gives us an idea about whether it was the starting 11 formation or was a tactical shift or any other developments in the teams. Let us generate a completely new dataset only focusing on the `tactics` and the `type` columns. We will filter the data in such a way that the `tactics` column has no rows set to `nan`.

```{python}
tact = events[events['tactics'].isnull() == False]
tact = tact[['tactics', 'team', 'type']]
print(tact.to_markdown())
```

Let us focus only on the tactics for the starting 11 set up from both the teams. We will build and analyze the pass network generated from among the starting 11 players from either of the teams. If we look into the first two rows of the `type` column in `tact`, we see that they are set as `'Starting XI'`, one for each team. Let us separately fetch the data for the teams, filtering by `type`

```{python}
tact = tact[tact['type'] == 'Starting XI']
tact_Real = tact[tact['team'] == 'Real Madrid']
tact_Liv = tact[tact['team'] == 'Liverpool']
tact_Real = tact_Real['tactics']
tact_Liv = tact_Liv['tactics']
```

Let us see how `tact_Real` and `tact_Barca` look:

```{python}
print(tact_Real.to_markdown())
```

```{python}
print(tact_Liv.to_markdown())
```

So both `tact_Real` and `tact_Liv` are dataframes made of single rows with their indices (Which we will use to extract the data), and the `tactics` column is made up of a Python `dict` object. For now we are only interested in the key `'lineup'` to get all the information about the players from the teams. 

```{python}
dict_Real = tact_Real[0]['lineup']
dict_Liv = tact_Liv[1]['lineup']
```

We will use the `from_dict()` function provided by `pandas` to convert the dictionary into a dataframe.

```{python}
lineup_Real = pd.DataFrame.from_dict(dict_Real)
print(lineup_Real.to_markdown())
```

```{python}
lineup_Liv = pd.DataFrame.from_dict(dict_Liv)
print(lineup_Liv.to_markdown())
```

We are basically interested in the players name and their corresponding jersey numbers. We will use a simple for loop and store the information in seperate dictionaries for both the teams.

```{python}
players_Real = {}
for i in range(len(lineup_Real)):
    key = lineup_Real.player[i]['name']
    val = lineup_Real.jersey_number[i]
    players_Real[key] = str(val)
print(players_Real)
```

```{python}
players_Liv = {}
for i in range(len(lineup_Liv)):
    key = lineup_Liv.player[i]['name']
    val = lineup_Liv.jersey_number[i]
    players_Liv[key] = str(val)
print(players_Liv)
```

So, we have collected the names and the jersey number of the players (starting 11) from both the teams in separate dictionaries named `players_Real` and `players_Liv`. These will come handy later!

Now from the `events` dataset we will extract out the relevant columns for our pass network analysis purposes.

```{python}
events_pn = events[['minute', 'second', 'team', 'type', 'location', 'pass_end_location', 'pass_outcome', 'player']]
```

```{python}
print(events_pn.head(10).to_markdown())
```

```{python}
print(events_pn.tail(10).to_markdown())
```

The next step is to filter the datset by teams and store them as new datasets:

```{python}
events_Real = events_pn[events_pn['team'] == 'Real Madrid']
events_Liv = events_pn[events_pn['team'] == 'Liverpool']
```

View the first 10 rows from both the datasets:

```{python}
print(events_Real.head(10).to_markdown())
print(events_Liv.head(10).to_markdown())
```

As we are only interested in the pass network generation, we will filter the datasets by keeping those rows where `type` is set to `Pass`.

```{python}
events_pn_Real = events_Real[events_Real['type'] == 'Pass']
events_pn_Liv = events_Liv[events_Liv['type'] == 'Pass']
```

Again view the first 10 rows of the filtered datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Let us now very carefully observe the datasets. Suppose from the `events_rn_Real` dataset, we are focusing on the second and the third row (index `1` and `2`). `Luka Modrić` makes the pass at around `0`th `minute` and `10`th `second` (Second row) and `Daniel Carvajal Ramos ` receives the pass at around `0`th `minute` and `11`th `second` (third row). So in both the datasets we need to add two extra columns named as `pass_maker` and `pass_receiver`, where `pass_maker` column would be similar to `player` column and the `pass_receiver` column would be the `player` column whose index would be shifted by one place in the negative direction. This can be achieved by the `shift()` function provided by `pandas`. We will perform this operation on both `events_pn_Real` and `events_pn_Liv`.

```{python warnings=FALSE}
events_pn_Real['pass_maker'] = events_pn_Real['player']
events_pn_Real['pass_receiver'] = events_pn_Real['player'].shift(-1)

events_pn_Liv['pass_maker'] = events_pn_Liv['player']
events_pn_Liv['pass_receiver'] = events_pn_Liv['player'].shift(-1)
```

Let us check now how the modified datasets look:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Now, there might be passes which were not successful. Remember from the [third post](https://realsoccerexpand.netlify.app/post/pass-map-shot-map-and-heat-map/) that in the statsbomb data passes whose `pass_outcome` are set as `nan` are actually the successful passes. We will again filter the datasets by successful passes:

```{python}
events_pn_Real = events_pn_Real[events_pn_Real['pass_outcome'].isnull() == True].reset_index()
events_pn_Liv = events_pn_Liv[events_pn_Liv['pass_outcome'].isnull() == True].reset_index()
```

The first 10 rows of the filtered datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

So it seems we have been able to logically clean and modify the datasets. Now we are only focused on building the pass netwrok among the players who were in the starting 11 from both the teams. So we will discard out the rows which consist of pass events that took place after the first substitution for either of the teams. Let us find the `minute` and `second` of the first substitution for both `Real Madrid` and `Liverpool`.

So let us filter the datasets `events_Real` and `events_Liv` by setting the `type` to be `Substitution`. This will give us the information of when the first substitution had taken place for the teams.

```{python}
substitution_Real = events_Real[events_Real['type'] == 'Substitution']
substitution_Liv = events_Liv[events_Liv['type'] == 'Substitution']
```

And let us view the datasets:

```{python}
print(substitution_Real.to_markdown())
print(substitution_Liv.to_markdown())
```

We see that the first substitution takes place for `Real Madrid` at the `36`th minute and `17`th second, whereas for `Liverpool` it takes place around `29`th minute and `39`th second. Let us find these out by writing a small Python code:

```{python}
substitution_Real_minute = np.min(substitution_Real['minute'])
substitution_Real_minute_data = substitution_Real[substitution_Real['minute'] == substitution_Real_minute]
substitution_Real_second = np.min(substitution_Real_minute_data['second'])
print("minute =", substitution_Real_minute, "second =",  substitution_Real_second)
```

```{python}
substitution_Liv_minute = np.min(substitution_Liv['minute'])
substitution_Liv_minute_data = substitution_Liv[substitution_Liv['minute'] == substitution_Liv_minute]
substitution_Liv_second = np.min(substitution_Liv_minute_data['second'])
print("minute = ", substitution_Liv_minute, "second = ", substitution_Liv_second)
```

We see that we have gotten the correct timings of when the first substitutions had taken place. Now we filter our datasets by taking tose pass events that took place before the first substitutions 

```{python}
events_pn_Real = events_pn_Real[(events_pn_Real['minute'] <= substitution_Real_minute)]

events_pn_Liv = events_pn_Liv[(events_pn_Liv['minute'] <= substitution_Liv_minute)]
```

Let us again print the first 10 rows of the renewed datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Now from the datasets, we will split the `location` and the `pass_end_location` columns into two columns each representing the coordinates and name them as `pass_maker_x`, `pass_maker_y`, `pass_receiver_x` and `pass_receiver_y`.

Let us manipulate the dataset for `Real Madrid` first:

```{python}
Loc = events_pn_Real['location']
Loc = pd.DataFrame(Loc.to_list(), columns=['pass_maker_x', 'pass_maker_y'])

Loc_end = events_pn_Real['pass_end_location']
Loc_end = pd.DataFrame(Loc_end.to_list(), columns=['pass_receiver_x', 'pass_receiver_y'])

events_pn_Real['pass_maker_x'] = Loc['pass_maker_x']
events_pn_Real['pass_maker_y'] = Loc['pass_maker_y']
events_pn_Real['pass_receiver_x'] = Loc_end['pass_receiver_x']
events_pn_Real['pass_receiver_y'] = Loc_end['pass_receiver_y']

events_pn_Real = events_pn_Real[['index', 'minute', 'second', 'team', 'type', 'pass_outcome', 'player', 'pass_maker', 'pass_receiver', 'pass_maker_x', 'pass_maker_y', 'pass_receiver_x', 'pass_receiver_y']]

print(events_pn_Real.head(10).to_markdown())
```

Same manipulation for Liverpool:

```{python}
Loc = events_pn_Liv['location']
Loc = pd.DataFrame(Loc.to_list(), columns=['pass_maker_x', 'pass_maker_y'])

Loc_end = events_pn_Liv['pass_end_location']
Loc_end = pd.DataFrame(Loc_end.to_list(), columns=['pass_receiver_x', 'pass_receiver_y'])

events_pn_Liv['pass_maker_x'] = Loc['pass_maker_x']
events_pn_Liv['pass_maker_y'] = Loc['pass_maker_y']
events_pn_Liv['pass_receiver_x'] = Loc_end['pass_receiver_x']
events_pn_Liv['pass_receiver_y'] = Loc_end['pass_receiver_y']

events_pn_Liv = events_pn_Liv[['index', 'minute', 'second', 'team', 'type', 'pass_outcome', 'player', 'pass_maker', 'pass_receiver', 'pass_maker_x', 'pass_maker_y', 'pass_receiver_x', 'pass_receiver_y']]

print(events_pn_Liv.head(10).to_markdown())
```

Inspired by the way given [here](https://mplsoccer.readthedocs.io/en/latest/gallery/pitch_plots/plot_pass_network.html), we will take the average locations of the starting 11 players on the field for a unified construction of the pass network, and also will count the number of passes created by these player:

```{python}
av_loc_Real = events_pn_Real.groupby('pass_maker').agg({'pass_maker_x':['mean'], 'pass_maker_y':['mean', 'count']})
print(av_loc_Real.to_markdown())
```

As we see the `groupby()` function from `pandas` splits `events_pn_Real` into groups indexed by the player names. Whereas, the `agg()` function aggregates the data into the averages of the pass makers' locations and also counts the number of passes made by these players. Now refine the column names of `av_loc_Real`:

```{python}
av_loc_Real.columns = ['pass_maker_x', 'pass_maker_y', 'count']
print(av_loc_Real.to_markdown())
```

Now do the same operations for `Liverpool`:

```{python}
av_loc_Liv = events_pn_Liv.groupby('pass_maker').agg({'pass_maker_x':['mean'], 'pass_maker_y':['mean', 'count']})
av_loc_Liv.columns = ['pass_maker_x', 'pass_maker_y', 'count']
print(av_loc_Liv.to_markdown())
```

Once we sort out the starting 11 pass makers' average locations in a game, we will try to figure out the number of times a particular pass maker passed the ball to a particular pass receiver (be cautious to keep the direction of pass in mind, i.e, a pass from a player `A` to a player `B` is not identical to a pass from player `B` to player `A`). We will use the `groupby()` and the `count()` function to count the number of rows where a unique player `A` passed the ball to another unique player `B`.

```{python}
pass_Real = events_pn_Real.groupby(['pass_maker', 'pass_receiver']).index.count().reset_index()
print(pass_Real.head(10).to_markdown())
```

```{python}
pass_Liv = events_pn_Liv.groupby(['pass_maker', 'pass_receiver']).index.count().reset_index()
print(pass_Liv.head(10).to_markdown())
```

Let's rename the `index` column to `number_of_passes`:

```{python}
pass_Real.rename(columns = {'index':'number_of_passes'}, inplace = True)
print(pass_Real.head(10).to_markdown())
```

```{python}
pass_Liv.rename(columns = {'index':'number_of_passes'}, inplace = True)
print(pass_Liv.head(10).to_markdown())
```

Now, we will merge the datasets `av_loc_Real` and `pass_Real`, Let us identify the left and the right dataframes for performing the merge. Here, `av_loc_Real` is the left dataframe and `pass_Real` is the right. We will use the `merge()` function from `pandas` to carry out the merging operation. 

```{python}
pass_Real = pass_Real.merge(av_loc_Real, left_on = 'pass_maker', right_index = True)
print(pass_Real.head(10).to_markdown())
```

The `left_on` argument specifies the column names to join our right dataframe on, and the `right_index` argument decides whether to use the index from the right dataframe as the key for joining. Let us do the same operation for the other team:

```{python}
pass_Liv = pass_Liv.merge(av_loc_Liv, left_on = 'pass_maker', right_index = True)
print(pass_Liv.head(10).to_markdown())
```

Finally, we will again perform a merge on these updated datasets for adding the average locations of the pass receivers and the number of times the receiver received the ball. A last touch of data cleaning will fetch us the dataset sufficient to start visualizing the pass networks for both the teams

```{python}
pass_Real = pass_Real.merge(av_loc_Real, left_on = 'pass_receiver', right_index = True, suffixes = ['', '_receipt'])
pass_Real.rename(columns = {'pass_maker_x_receipt':'pass_receiver_x', 'pass_maker_y_receipt':'pass_receiver_y', 'count_receipt':'number_of_passes_received'}, inplace = True)
pass_Real = pass_Real[pass_Real['pass_maker'] != pass_Real['pass_receiver']].reset_index()
print(pass_Real.to_markdown())
```

```{python}
pass_Liv = pass_Liv.merge(av_loc_Liv, left_on = 'pass_receiver', right_index = True, suffixes = ['', '_receipt'])
pass_Liv.rename(columns = {'pass_maker_x_receipt':'pass_receiver_x', 'pass_maker_y_receipt':'pass_receiver_y', 'count_receipt':'number_of_passes_received'}, inplace = True)
pass_Liv = pass_Liv[pass_Liv['pass_maker'] != pass_Liv['pass_receiver']].reset_index()
print(pass_Liv.to_markdown())
```

We will replace the player names with their jersey numbers and create another pair of new datasets:

```{python}
pass_Real_new = pass_Real.replace({"pass_maker": players_Real, "pass_receiver": players_Real})
print(pass_Real_new.to_markdown())
```

```{python}
pass_Liv_new = pass_Liv.replace({"pass_maker": players_Liv, "pass_receiver": players_Liv})
print(pass_Liv_new.to_markdown())
```

Now let us visualize the pass networks for both the teams.

```{python results=FALSE}
pitch = Pitch(pitch_color='grass', goal_type = 'box', line_color='white', stripe = True, constrained_layout=True, tight_layout=False)
fig, ax = pitch.draw()
arrows = pitch.arrows(pass_Real.pass_maker_x, pass_Real.pass_maker_y,
                         pass_Real.pass_receiver_x, pass_Real.pass_receiver_y, lw = 5,
                         color = 'black', zorder = 1, ax = ax)
nodes = pitch.scatter(av_loc_Real.pass_maker_x, av_loc_Real.pass_maker_y,
                           s=350, color = 'white', edgecolors='black', linewidth=1, alpha = 1, ax = ax)
                          
for index, row in av_loc_Real.iterrows():
    pitch.annotate(players_Real[row.name], xy=(row.pass_maker_x, row.pass_maker_y), c ='black', va = 'center', ha = 'center', size = 10, ax = ax)
plt.title("Pass network for Real Madrid against Liverpool", size = 20)                   
plt.show()
```

```{python results=FALSE}
pitch = Pitch(pitch_color='grass', goal_type = 'box', stripe = True, line_color='white', constrained_layout=True, tight_layout=False)
fig, ax = pitch.draw()
arrows = pitch.arrows(120 - pass_Liv.pass_maker_x, pass_Liv.pass_maker_y,
                         120 - pass_Liv.pass_receiver_x, pass_Liv.pass_receiver_y, lw = 5,
                         color = 'black', zorder = 1, ax = ax)
nodes = pitch.scatter(120 - av_loc_Liv.pass_maker_x, av_loc_Liv.pass_maker_y,
                           s=350, color = 'red', edgecolors = 'black', linewidth=1, alpha = 1, ax = ax)
                           
for index, row in av_loc_Liv.iterrows():
    pitch.annotate(players_Liv[row.name], xy=(120 - row.pass_maker_x, row.pass_maker_y), c ='black', va = 'center', ha = 'center', size = 10, ax = ax)
plt.title("Pass network for Liverpool against Real Madrid", size = 20)
plt.show()
```

In case of `Liverpool`'s pass network visualization, we subtract the x coordinates from 120 just to reverse the x-axis. Now that we have been successful in correctly visualizing the pass networks of the teams involved in the game, we will now start analyzing our networks using metrics from the literature of *complex network analysis*.

Note that both of our networks are directed weighted graphs, with number of passes as the weight for a directed edge.

Let us first develop the isomorphic graph to the one we just visualized for `Real Madrid`, but this time using the `networkx` package. First we will use the relevant columns from the `pass_Real_new` dataset:

```{python}
pass_Real_new = pass_Real_new[['pass_maker', 'pass_receiver', 'number_of_passes']]
print(pass_Real_new.to_markdown())
```

We will next convert `pass_Real_new` to a list of tuples, where each row is converted to a tuple. This is required for drawing a `networkx` graph

```{python}
L_Real = pass_Real_new.apply(tuple, axis=1).tolist()
print(L_Real)
```

Now, we can draw the directed weighted graph:

```{python results=FALSE}
G_Real = nx.DiGraph()

for i in range(len(L_Real)):
    G_Real.add_edge(L_Real[i][0], L_Real[i][1], weight = L_Real[i][2])

edges_Real = G_Real.edges()
weights_Real = [G_Real[u][v]['weight'] for u, v in edges_Real]

nx.draw(G_Real, node_size=800, with_labels=True, node_color='white', width = weights_Real)
plt.gca().collections[0].set_edgecolor('black') # sets the edge color of the nodes to black
plt.title("Pass network for Real Madrid vs Liverpool", size = 20)
plt.show()
```

Now for `Liverpool` too, let us first clean the `pass_Liv_new` dataset and then draw the isomorphic weighted directed graph:

```{python}
pass_Liv_new = pass_Liv_new[['pass_maker', 'pass_receiver', 'number_of_passes']]
print(pass_Liv_new.to_markdown())
```


```{python}
L_Liv = pass_Liv_new.apply(tuple, axis=1).tolist()
G_Liv = nx.DiGraph()

for i in range(len(L_Liv)):
    G_Liv.add_edge(L_Liv[i][0], L_Liv[i][1], weight = L_Liv[i][2])

edges_Liv = G_Liv.edges()
weights_Liv = [G_Liv[u][v]['weight'] for u, v in edges_Liv]

nx.draw(G_Liv, node_size = 800, with_labels = True, node_color = 'red', width = weights_Liv)
plt.gca().collections[0].set_edgecolor('black') # sets the edge color of the nodes to black
plt.show()
```

Let us discuss some of the important functions from the `networkx` package that we have employed for drawing graphs:

* `DiGraph()` function sets the base class for generating directed graphs,
* `add_edge()` function adds an edge between two nodes given by the first two arguments and the `weight` parameter sets the weight for this edge
* `draw()` function visualizes a `networkx` graph and its parameters are self-explanatory

Let us now understand the *degree*, *indegree* and *outdegree* of a node from a directed weighted graph. *Indegree* of a node is the total number of edges that are directed towards the node, i.e, for our case, the total number of passes received by a player (node). Similarly, *outdegree* means the total number of edges that are directed outwards from the node, i.e, the total number of passes given by a player. Finally, the *degree* of a node is the total number of edges connected to a node (ignoring the directions of the edges), i.e, sum of the total number of passes given and the total number of passes received by a player. It is evident that the *degree* of a node is the sum of its *indegree* and *outdegree*.

We will use `networkx` to find out the node degrees from the pass network of `Real Madrid`.

```{python}
deg_Real = dict(nx.degree(G_Real)) # prepares a dictionary with jersey numbers as the node ids, i.e, the dictionary keys and degrees as the dictionary values
degree_Real = pd.DataFrame.from_dict(list(deg_Real.items())) # convert a dictionary to a pandas dataframe
degree_Real.rename(columns = {0:'jersey_number', 1: 'node_degree'}, inplace = True)
print(degree_Real.to_markdown())
```

Out of the 11 starting players for `Real Madrid` in that game, we notice that the player with jersey number `8` (i.e, `Toni Kroos`) had the highest *degree* value of 19. On second are ranked the players with jersey number `2` and `4` with degree value 17, i.e, our favorite Spanish defenders `'Daniel Carvajal Ramos'` and `'Sergio Ramos García'` respectively. Tremendous! Let us use `seaborn` to visualize the `deg_Real` dictionary via histogram plot:

```{python results=FALSE}
X = list(deg_Real.keys())
Y = list(deg_Real.values())
sns.barplot(x = Y, y = X, palette = "magma")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("degree")
plt.title("Player pass degrees for Real Madrid vs Liverpool", size = 16)
plt.show()
```

Let us build the dataframe for `Liverpool` too:

```{python}
deg_Liv = dict(nx.degree(G_Liv)) # prepares a dictionary with jersey numbers as the node ids, i.e, the dictionary keys and degrees as the dictionary values
degree_Liv = pd.DataFrame.from_dict(list(deg_Liv.items())) # convert a dictionary to a pandas dataframe
degree_Liv.rename(columns = {0:'jersey_number', 1: 'node_degree'}, inplace = True)
print(degree_Liv.to_markdown())
```

We see that for Liverpool the degree value is highest (17) for players having jersey number `14` and `7`, i,e `'Jordan Brian Henderson'` and `'James Philip Milner'` respectively. We will visualize the `deg_Liv` dictionary via histogram plot:

```{python results=FALSE}
X = list(deg_Liv.keys())
Y = list(deg_Liv.values())
sns.barplot(x = Y, y = X, palette = "magma")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("degree")
plt.title("Player pass degrees for Liverpool vs Real Madrid", size = 16)
plt.show()
```

We will visualize similar histogram plots for the *indegrees* and the *outdegrees* too:

```{python results=FALSE}
indeg_Real = dict(G_Real.in_degree()) 
indegree_Real = pd.DataFrame.from_dict(list(indeg_Real.items())) 
indegree_Real.rename(columns = {0:'jersey_number', 1: 'node_indegree'}, inplace = True)
print(indegree_Real.to_markdown())

X = list(indeg_Real.keys())
Y = list(indeg_Real.values())
sns.barplot(x = Y, y = X, palette = "hls")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("indegree")
plt.title("Player pass indegrees for Real Madrid vs Liverpool", size = 16)
plt.show()
```

```{python results=FALSE}
indeg_Liv = dict(G_Liv.in_degree()) 
indegree_Liv = pd.DataFrame.from_dict(list(indeg_Liv.items())) 
indegree_Liv.rename(columns = {0:'jersey_number', 1: 'node_indegree'}, inplace = True)
print(indegree_Liv.to_markdown())

X = list(indeg_Liv.keys())
Y = list(indeg_Liv.values())
sns.barplot(x = Y, y = X, palette = "hls")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("indegree")
plt.title("Player pass indegrees for Liverpool vs Real Madrid", size = 16)
plt.show()
```

```{python results=FALSE}
outdeg_Real = dict(G_Real.out_degree()) 
outdegree_Real = pd.DataFrame.from_dict(list(outdeg_Real.items())) 
outdegree_Real.rename(columns = {0:'jersey_number', 1: 'node_outdegree'}, inplace = True)
print(outdegree_Real.to_markdown())

X = list(outdeg_Real.keys())
Y = list(outdeg_Real.values())
sns.barplot(x = Y, y = X, palette = "hls")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("outdegree")
plt.title("Player pass outdegrees for Real Madrid vs Liverpool", size = 16)
plt.show()
```

```{python results=FALSE}
outdeg_Liv = dict(G_Liv.out_degree()) 
outdegree_Liv = pd.DataFrame.from_dict(list(outdeg_Liv.items())) 
outdegree_Liv.rename(columns = {0:'jersey_number', 1: 'node_outdegree'}, inplace = True)
print(outdegree_Liv.to_markdown())

X = list(outdeg_Liv.keys())
Y = list(outdeg_Liv.values())
sns.barplot(x = Y, y = X, palette = "hls")
plt.xticks(range(0, max(Y)+5, 2))
plt.ylabel("Player Jersey number")
plt.xlabel("outdegree")
plt.title("Player pass outdegrees for Liverpool vs Real Madrid", size = 16)
plt.show()
```

Now, let us generate the adjacency matrices fr both `G_Real` and `G_Liv` graphs:

```{python results=FALSE}
A_Real = nx.adjacency_matrix(G_Real)
A_Liv = nx.adjacency_matrix(G_Liv)
A_Real = A_Real.todense()
A_Liv = A_Liv.todense()
```

We can visualize the matrices as heatmaps:

```{python results=FALSE}
sns.heatmap(A_Real, annot = True, cmap ='gnuplot')
plt.title("Adjacency matrix for Real Madrid's pass network")
plt.show()
```

```{python results=FALSE}
sns.heatmap(A_Liv, annot = True, cmap ='gnuplot')
plt.title("Adjacency matrix for Liverpool's pass network")
plt.show()
```

If we look into the diagonal of the adjacency matrices, we notice that all the values in the diagonals are 0. This depicts that their isn't any self loops in any nodes, indicating a player cannot pass to themselves. 

The next step is to calculate the degree correlation coefficient of a graph. More specifically, we will calculate *Pearson's degree correlation coefficient* value. A positive value of the metric shows an overall positive relationship between the degrees (number of successful passes) of two adjacent nodes (players). Whereas a negative value shows an overall negative relationship. If it is 0, there is no relationship. Also the metric lies in [-1, 1], indicating -1 as the prefect negative relationship and 1 as the perfect positive relationship.

```{python}
r_Real = nx.degree_pearson_correlation_coefficient(G_Real, weight = 'weight')
r_Liv = nx.degree_pearson_correlation_coefficient(G_Liv, weight = 'weight')
print(r_Real, r_Liv)
```

Now we work on a metric that focuses on the geodesic distance between two player nodes in a graph. One way to implement this is to divide 1 by the `'weight'` column in the pass network. Let us create a new graph for `Real Madrid`:

```{python}
pass_Real_mod = pass_Real_new[['pass_maker', 'pass_receiver']]
pass_Real_mod['1/nop'] = 1/pass_Real_new['number_of_passes']
print(pass_Real_mod.head(5).to_markdown())
```

```{python results=FALSE}
L_Real_mod = pass_Real_mod.apply(tuple, axis=1).tolist()

G_Real_mod = nx.DiGraph()

for i in range(len(L_Real_mod)):
    G_Real_mod.add_edge(L_Real_mod[i][0], L_Real_mod[i][1], weight = L_Real_mod[i][2])

edges_Real_mod = G_Real_mod.edges()
weights_Real_mod = [G_Real_mod[u][v]['weight'] for u, v in edges_Real_mod]

nx.draw(G_Real_mod, node_size=800, with_labels=True, node_color='white', width = weights_Real_mod)
plt.gca().collections[0].set_edgecolor('black')
plt.title("Modified pass network for Real Madrid vs Liverpool", size = 20)

plt.show()
```

We will perform the same operations to create a modified graph for `Liverpool` too:

```{python}
pass_Liv_mod = pass_Liv_new[['pass_maker', 'pass_receiver']]
pass_Liv_mod['1/nop'] = 1/pass_Liv_new['number_of_passes']
print(pass_Liv_mod.head(5).to_markdown())
```

```{python results=FALSE}
L_Liv_mod = pass_Liv_mod.apply(tuple, axis=1).tolist()

G_Liv_mod = nx.DiGraph()

for i in range(len(L_Liv_mod)):
    G_Liv_mod.add_edge(L_Liv_mod[i][0], L_Liv_mod[i][1], weight = L_Liv_mod[i][2])

edges_Liv_mod = G_Liv_mod.edges()
weights_Liv_mod = [G_Liv_mod[u][v]['weight'] for u, v in edges_Liv_mod]

nx.draw(G_Liv_mod, node_size=800, with_labels=True, node_color='red', width = weights_Liv_mod)
plt.gca().collections[0].set_edgecolor('black')
plt.title("Modified pass network for Liverpool vs Real Madrid", size = 20)

plt.show()
```

Now using these modified graphs we can calculate the all pair shortest paths between the nodes (players) for both the teams. Let us compute first for `Real Madrid`:

```{python}
dis_Real = nx.shortest_path(G_Real_mod, weight = 'weight')
print(dis_Real)
```

Suppose we want to calculate the shortest path from `'Keylor Navas Gamboa'` (jersey number `1`) to `'Cristiano Ronaldo dos Santos Aveiro'` (jersey number `7`). We will type the following:

```{python}
print(dis_Real['1']['7'])
```

So, we see that the fastest way possible to pass the ball from `'Keylor Navas Gamboa'` (jersey: `1`), to  `'Cristiano Ronaldo dos Santos Aveiro'` (jersey: `7`) was to pass the ball first to `'Sergio Ramos García'` (jersey: `4`) who would pass to `'Marcelo Vieira da Silva Júnior'` (jersey: `12`) with him ultimately passing to `'Cristiano Ronaldo dos Santos Aveiro'`. This seems like a good post-match analysis tool. I got this idea after discussing with [Sarath Babu](https://4sarathbabu.github.io/). 

Let us do the same analysis for `Liverpool`:

```{python}
dis_Liv = nx.shortest_path(G_Liv_mod, weight = 'weight')
print(dis_Liv)
```

```{python}
print(dis_Liv['1']['9'])
```

Now we will calculate another important metric called *eccentricity*, which is based on shortest distance. *Eccentricity*  of a player node `p` tells us how far the furthest player node from `p` is positioned in the pass network. Let us calculate the eccentricities for all the 11 nodes for `Real Madrid`.

```{python}
E_Real = nx.eccentricity(G_Real_mod)
print(E_Real)
```

We can calculate the average eccentricity:

```{python}
av_E_Real = sum(list(E_Real.values()))/len(E_Real)
print(av_E_Real)
```

For `Liverpool`:

```{python}
E_Liv = nx.eccentricity(G_Liv_mod)
print(E_Liv)
```

We can calculate the *average eccentricity*:

```{python}
av_E_Liv = sum(list(E_Liv.values()))/len(E_Liv)
print(av_E_Liv)
```

We can also calculate the *average clustering coefficient* of a graph. Let us first compute this metric for `G_Real` (note that this graph should not be the modified version)

```{python}
cc_Real = nx.average_clustering(G_Real, weight = 'weight')
print(cc_Real)
```

for `Liverpool`:

```{python}
cc_Liv = nx.average_clustering(G_Liv, weight = 'weight')
print(cc_Liv)
```

The *average clustering coefficient* lies in the range [0, 1] where, a value of 0 denotes the fact that none of the nodes are connected to each other and a value of 1 denotes that the network is a clique, that is each node is connected to all the other nodes of the network. We see that interestingly the *average clustering coefficient* is lesser for `Real Madrid`'s pass network stating the fact that a lesser number of players passed the ball among each other, compared to that of `Liverpool`.

Finally, we can compute the `centrality` (especially the `betweenness centrality`) for each node in either team's pass network and understand which player was the most important in their pass network. For `Real Madrid`:

```{python}
bc_Real = nx.betweenness_centrality(G_Real, weight = 'weight')
print(bc_Real)
```

we can find the node which has the maximum *betweenness centrality* measure.

```{python}
max_bc_Real = max(bc_Real, key = bc_Real.get)
print(max_bc_Real)
```


For `Liverpool`:

```{python}
bc_Liv = nx.betweenness_centrality(G_Liv, weight = 'weight')
print(bc_Liv)
max_bc_Liv = max(bc_Liv, key = bc_Liv.get)
print(max_bc_Liv)
```

So we see that the *betweenness centrality* measure is max for `'Carlos Henrique Casimiro'` (jersey: `4`) from `Real Madrid` and `'James Philip Milner'` (jersey: 7) from `Liverpool`. We have been able to compute some interesting results using complex network analysis on our pass networks. This completes the current tutorial.😌😌😌😌😌😌😌😌😌

In the next tutorial, I will introduce how to implement ideas from *computational geometry* on football data and generate some intuitive visualizations. 

