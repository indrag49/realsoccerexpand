---
title: Pass Network Analysis
author: Indranil Ghosh
date: '2021-04-28'
slug: pass-network-analysis
categories: ["Python", "visualization", "NetworkX"]
tags: ["statsbomb api", "NetworkX", "Network Analysis", "Pass Network"]
subtitle: ''
summary: ''
authors: []
lastmod: '2021-04-28T10:15:58+05:30'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

In our [last tutorial](https://realsoccerexpand.netlify.app/post/pass-map-shot-map-and-heat-map/) we studied how to draw a pass map, a shot map and their corresponding heat maps. We used statsbomb's open even data from the match between *Real Madrid* and *Barcelona*, which *Real Madrid* ended up winning 2-0. In this post we will again use statsbomb's open event passing data (from a separate game this time, which we will decide on the go) and visualize the resulting pass network of a particular team on the football pitch. We will then use basic concepts from complex network analysis literature to further analyze the network and deduce some results. We will employ the [`NetworkX`](https://networkx.org/) Python package for the analysis purpose. 

Let us `pip` install the package:

```{python eval=FALSE}
pip install networkx
```

After installing the package we will import all the necessary packages and modules:

```{python}
from statsbombpy import sb # statsbomb api
import matplotlib.pyplot as plt # matplotlib for plotting
from mplsoccer.pitch import Pitch # for drawing the football pitch
import seaborn as sns # seaborn for plotting useful statistical graphs
import numpy as np # numerical python package
import pandas as pd # pandas for manipulating and analysing data
import networkx as nx # package for complex network analysis
```

Let us again work step by step to fetch the event data from a particular match:

```{python results=FALSE}
comp = sb.competitions()
```

```{python}
print(comp.to_markdown())
```

Let us use the first row from `comp` where the `competition_id` is `16` and `season_id` is `4`. We see that it holds the event data from *UEFA Champions League* ⚽ for the 2017-18 season. Let us now extract out the matches using the above information.

```{python results=FALSE}
mat = sb.matches(competition_id = 16, season_id = 1)
```

```{python}
print(mat.to_markdown())
```

We see there is only one match available, having `match_id` set to `18245`. It represents the final that took place between *Real Madrid* and *Liverpool* at *Olimpiyskiy National Sports Complex, Moscow* and Real Madrid won with the full time score: 3-1. Finally let us draw out the complete event data from this match:

```{python results=FALSE}
events = sb.events(match_id = 18245)
```

We will print the first and the last 10 rows of the dataset to get an idea of how it looks and what information it provides us with:

```{python}
print(events.head(10).to_markdown())
```

```{python}
print(events.tail(10).to_markdown())
```

As we have been usually doing till now, let us print out the column names of `events` to get an overview of the relevant and the unnecessary rows for this tutorial.

```{python}
print(events.columns)
```

If we look into the `events` dataset, we notice that the `tactics` column provides us with team lineups, formations, player ids and their jersey number from both the teams. The corresponding row values for column `type` gives us an idea about whether it was the starting 11 formation or was a tactical shift or any other developments in the teams. Let us generate a completely new dataset only focusing on the `tactics` and the `type` columns. We will filter the data in such a way that the `tactics` column has no rows set to `nan`.

```{python}
tact = events[events['tactics'].isnull() == False]
tact = tact[['tactics', 'team', 'type']]
print(tact.to_markdown())
```

Let us focus only on the tactics for the starting 11 set up from both the teams. We will build and analyze the pass network generated from among the starting 11 players from either of the teams. If we look into the first two rows of the `type` column in `tact`, we see that they are set as `'Starting XI'`, one for each team. Let us separately fetch the data for the teams, filtering by `type`

```{python}
tact = tact[tact['type'] == 'Starting XI']
tact_Real = tact[tact['team'] == 'Real Madrid']
tact_Liv = tact[tact['team'] == 'Liverpool']
tact_Real = tact_Real['tactics']
tact_Liv = tact_Liv['tactics']
```

Let us see how `tact_Real` and `tact_Barca` look:

```{python}
print(tact_Real.to_markdown())
```

```{python}
print(tact_Liv.to_markdown())
```

So both `tact_Real` and `tact_Liv` are dataframes made of single rows with their indices (Which we will use to extract the data), and the `tactics` column is made up of a Python `dict` object. For now we are only interested in the key `'lineup'` to get all the information about the players from the teams. 

```{python}
dict_Real = tact_Real[0]['lineup']
dict_Liv = tact_Liv[1]['lineup']
```

We will use the `from_dict()` function provided by `pandas` to convert the dictionary into a dataframe.

```{python}
lineup_Real = pd.DataFrame.from_dict(dict_Real)
print(lineup_Real.to_markdown())
```

```{python}
lineup_Liv = pd.DataFrame.from_dict(dict_Liv)
print(lineup_Liv.to_markdown())
```

We are basically interested in the players name and their corresponding jersey numbers. We will use a simple for loop and store the information in seperate dictionaries for both the teams.

```{python}
players_Real = {}
for i in range(len(lineup_Real)):
    key = lineup_Real.player[i]['name']
    val = lineup_Real.jersey_number[i]
    players_Real[key] = val
print(players_Real)
```

```{python}
players_Liv = {}
for i in range(len(lineup_Liv)):
    key = lineup_Liv.player[i]['name']
    val = lineup_Liv.jersey_number[i]
    players_Liv[key] = val
print(players_Liv)
```

So, we have collected the names and the jersey number of the players (starting 11) from both the teams in separate dictionaries named `players_Real` and `players_Liv`. These will come handy later!

Now from the `events` dataset we will extract out the relevant columns for our pass network analysis purposes.

```{python}
events_pn = events[['minute', 'second', 'team', 'type', 'location', 'pass_end_location', 'pass_outcome', 'player']]
```

```{python}
print(events_pn.head(10).to_markdown())
```

```{python}
print(events_pn.tail(10).to_markdown())
```

The next step is to filter the datset by teams and store them as new datasets:

```{python}
events_Real = events_pn[events_pn['team'] == 'Real Madrid']
events_Liv = events_pn[events_pn['team'] == 'Liverpool']
```

View the first 10 rows from both the datasets:

```{python}
print(events_Real.head(10).to_markdown())
print(events_Liv.head(10).to_markdown())
```

As we are only interested in the pass network generation, we will filter the datasets by keeping those rows where `type` is set to `Pass`.

```{python}
events_pn_Real = events_Real[events_Real['type'] == 'Pass']
events_pn_Liv = events_Liv[events_Liv['type'] == 'Pass']
```

Again view the first 10 rows of the filtered datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Let us now very carefully observe the datasets. Suppose from the `events_rn_Real` dataset, we are focusing on the second and the third row (index `1` and `2`). `Luka Modrić` makes the pass at around `0`th `minute` and `10`th `second` (Second row) and `Daniel Carvajal Ramos ` receives the pass at around `0`th `minute` and `11`th `second` (third row). So in both the datasets we need to add two extra columns named as `pass_maker` and `pass_receiver`, where `pass_maker` column would be similar to `player` column and the `pass_receiver` column would be the `player` column whose index would be shifted by one place in the negative direction. This can be achieved by the `shift()` function provided by `pandas`. We will perform this operation on both `events_pn_Real` and `events_pn_Liv`.

```{python warnings=FALSE}
events_pn_Real['pass_maker'] = events_pn_Real['player']
events_pn_Real['pass_receiver'] = events_pn_Real['player'].shift(-1)

events_pn_Liv['pass_maker'] = events_pn_Liv['player']
events_pn_Liv['pass_receiver'] = events_pn_Liv['player'].shift(-1)
```

Let us check now how the modified datasets look:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Now, there might be passes which were not successful. Remember from the [third post](https://realsoccerexpand.netlify.app/post/pass-map-shot-map-and-heat-map/) that in the statsbomb data passes whose `pass_outcome` are set as `nan` are actually the successful passes. We will again filter the datasets by successful passes:

```{python}
events_pn_Real = events_pn_Real[events_pn_Real['pass_outcome'].isnull() == True].reset_index()
events_pn_Liv = events_pn_Liv[events_pn_Liv['pass_outcome'].isnull() == True].reset_index()
```

The first 10 rows of the filtered datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

So it seems we have been able to logically clean and modify the datasets. Now we are only focused on building the pass netwrok among the players who were in the starting 11 from both the teams. So we will discard out the rows which consist of pass events that took place after the first substitution for either of the teams. Let us find the `minute` and `second` of the first substitution for both `Real Madrid` and `Barcelona`.

So let us filter the datasets `events_Real` and `events_Liv` by setting the `type` to be `Substitution`. This will give us the information of when the first substitution had taken place for the teams.

```{python}
substitution_Real = events_Real[events_Real['type'] == 'Substitution']
substitution_Liv = events_Liv[events_Liv['type'] == 'Substitution']
```

And let us view the datasets:

```{python}
print(substitution_Real.to_markdown())
print(substitution_Liv.to_markdown())
```

We see that the first substitution takes place for `Real Madrid` at the `36`th minute and `17`th second, whereas for `Liverpool` it takes place around `29`th minute and `39`th second. Let us find these out by writing a small Python code:

```{python}
substitution_Real_minute = np.min(substitution_Real['minute'])
substitution_Real_minute_data = substitution_Real[substitution_Real['minute'] == substitution_Real_minute]
substitution_Real_second = np.min(substitution_Real_minute_data['second'])
print("minute =", substitution_Real_minute, "second =",  substitution_Real_second)
```

```{python}
substitution_Liv_minute = np.min(substitution_Liv['minute'])
substitution_Liv_minute_data = substitution_Liv[substitution_Liv['minute'] == substitution_Liv_minute]
substitution_Liv_second = np.min(substitution_Liv_minute_data['second'])
print("minute = ", substitution_Liv_minute, "second = ", substitution_Liv_second)
```

We see that we have gotten the correct timings of when the first substitutions had taken place. Now we filter our datasets by taking tose pass events that took place before the first substitutions 

```{python}
events_pn_Real = events_pn_Real[(events_pn_Real['minute'] <= substitution_Real_minute)]

events_pn_Liv = events_pn_Liv[(events_pn_Liv['minute'] <= substitution_Liv_minute)]
```

Let us again print the first 10 rows of the renewed datasets:

```{python}
print(events_pn_Real.head(10).to_markdown())
print(events_pn_Liv.head(10).to_markdown())
```

Now from the datasets, we will split the `location` and the `pass_end_location` columns into two columns each representing the coordinates and name them as `pass_maker_x`, `pass_maker_y`, `pass_receiver_x` and `pass_receiver_y`.

Let us manipulate the dataset for `Real Madrid` first:

```{python}
Loc = events_pn_Real['location']
Loc = pd.DataFrame(Loc.to_list(), columns=['pass_maker_x', 'pass_maker_y'])

Loc_end = events_pn_Real['pass_end_location']
Loc_end = pd.DataFrame(Loc_end.to_list(), columns=['pass_receiver_x', 'pass_receiver_y'])

events_pn_Real['pass_maker_x'] = Loc['pass_maker_x']
events_pn_Real['pass_maker_y'] = Loc['pass_maker_y']
events_pn_Real['pass_receiver_x'] = Loc_end['pass_receiver_x']
events_pn_Real['pass_receiver_y'] = Loc_end['pass_receiver_y']

events_pn_Real = events_pn_Real[['index', 'minute', 'second', 'team', 'type', 'pass_outcome', 'player', 'pass_maker', 'pass_receiver', 'pass_maker_x', 'pass_maker_y', 'pass_receiver_x', 'pass_receiver_y']]

print(events_pn_Real.head(10).to_markdown())
```

Same manipulation for Liverpool:

```{python}
Loc = events_pn_Liv['location']
Loc = pd.DataFrame(Loc.to_list(), columns=['pass_maker_x', 'pass_maker_y'])

Loc_end = events_pn_Liv['pass_end_location']
Loc_end = pd.DataFrame(Loc_end.to_list(), columns=['pass_receiver_x', 'pass_receiver_y'])

events_pn_Liv['pass_maker_x'] = Loc['pass_maker_x']
events_pn_Liv['pass_maker_y'] = Loc['pass_maker_y']
events_pn_Liv['pass_receiver_x'] = Loc_end['pass_receiver_x']
events_pn_Liv['pass_receiver_y'] = Loc_end['pass_receiver_y']

events_pn_Liv = events_pn_Liv[['index', 'minute', 'second', 'team', 'type', 'pass_outcome', 'player', 'pass_maker', 'pass_receiver', 'pass_maker_x', 'pass_maker_y', 'pass_receiver_x', 'pass_receiver_y']]

print(events_pn_Liv.head(10).to_markdown())
```

Inspired by the way given [here](https://mplsoccer.readthedocs.io/en/latest/gallery/pitch_plots/plot_pass_network.html), we will take the average locations of the starting 11 players on the field for a unified construction of the pass network, and also will count the number of passes created by these player:

```{python}
av_loc_Real = events_pn_Real.groupby('pass_maker').agg({'pass_maker_x':['mean'], 'pass_maker_y':['mean', 'count']})
print(av_loc_Real.to_markdown())
```

As we see the `groupby()` function from `pandas` splits `events_pn_Real` into groups indexed by the player names. Whereas, the `agg()` function aggregates the data into the averages of the pass makers' locations and also counts the number of passes made by these players. Now refine the column names of `av_loc_Real`:

```{python}
av_loc_Real.columns = ['pass_maker_x', 'pass_maker_y', 'count']
print(av_loc_Real.to_markdown())
```

Now do the same operations for `Liverpool`:

```{python}
av_loc_Liv = events_pn_Liv.groupby('pass_maker').agg({'pass_maker_x':['mean'], 'pass_maker_y':['mean', 'count']})
av_loc_Liv.columns = ['pass_maker_x', 'pass_maker_y', 'count']
print(av_loc_Liv.to_markdown())
```

Once we sort out the starting 11 pass makers' average locations in a game, we will try to figure out the number of times a particular pass maker passed the ball to a particular pass receiver (be cautious to keep the direction of pass in mind, i.e, a pass from a player `A` to a player `B` is not identical to a pass from player `B` to player `A`). We will use the `groupby()` and the `count()` function to count the number of rows where a unique player `A` passed the ball to another unique player `B`.

```{python}
pass_Real = events_pn_Real.groupby(['pass_maker', 'pass_receiver']).index.count().reset_index()
print(pass_Real.head(10).to_markdown())
```

```{python}
pass_Liv = events_pn_Liv.groupby(['pass_maker', 'pass_receiver']).index.count().reset_index()
print(pass_Liv.head(10).to_markdown())
```

Let's rename the `index` column to `number_of_passes`:

```{python}
pass_Real.rename(columns = {'index':'number_of_passes'}, inplace = True)
print(pass_Real.head(10).to_markdown())
```

```{python}
pass_Liv.rename(columns = {'index':'number_of_passes'}, inplace = True)
print(pass_Liv.head(10).to_markdown())
```